# ğŸš€ Chatbot Local com IA â€” 100% Offline, Privado e Gratuito

Este projeto implementa um **chatbot de InteligÃªncia Artificial totalmente local**, rodando em sua mÃ¡quina sem usar APIs pagas, sem enviar dados para a internet e sem depender de serviÃ§os externos.

Ele utiliza o modelo **Llama 2 7B Chat** no formato **GGUF**, carregado pelo backend otimizado `llama-cpp-python`, garantindo desempenho mesmo em CPUs comuns.

O objetivo Ã© servir como um projeto de portfÃ³lio sÃ³lido, demonstrando conhecimento prÃ¡tico em:

* **Modelos LLM (Large Language Models)**
* **ExecuÃ§Ã£o local de IA**
* **Python**
* **ConstruÃ§Ã£o de prompts**
* **Manuseio de contexto / histÃ³rico de conversas**
* **Arquitetura simples, clara e eficiente**

---

## ğŸ“Œ Funcionalidades

* ğŸ¤– **Chatbot inteligente** que roda na sua mÃ¡quina
* ğŸ”’ **Zero internet** â€” total privacidade
* ğŸ§  **IA open-source** usando Llama 2
* ğŸ’¬ **HistÃ³rico de conversas** com contexto
* ğŸ†“ **100% gratuito**

---

## ğŸ› ï¸ Tecnologias Utilizadas

* **Python 3.11**
* `llama-cpp-python`
* **Modelos LLM** no formato **GGUF**
* VSCode / PowerShell
---

## ğŸ§  Como o chatbot funciona
* **Este projeto utiliza um Large Language Model (LLM): um modelo treinado em bilhÃµes de palavras para aprender padrÃµes da linguagem humana.**

Etapas internas:

- VocÃª envia uma mensagem.

- O cÃ³digo constrÃ³i um prompt, incluindo histÃ³rico e instruÃ§Ãµes.

- O modelo Llama 2 processa o texto e prevÃª a prÃ³xima palavra.

- A IA repete esse processo milhares de vezes por segundo.

- O modelo devolve uma resposta completa e coerente.

Importante: NÃ£o hÃ¡ regras programadas. A inteligÃªncia emerge do treinamento massivo do modelo.

## ğŸ¯ Objetivo do Projeto
- Este projeto foi criado para:

- Demonstrar habilidades com IA moderna

- Apresentar domÃ­nio prÃ¡tico de LLMs em Python

- Construir um chatbot totalmente funcional

- Garantir privacidade (nenhum dado sai da sua mÃ¡quina)

## ğŸ“¦ InstalaÃ§Ã£o

### 1. Clone o repositÃ³rio

- git clone [https://github.com/brianashihara/MiniChatDemo.git](https://github.com/brianashihara/MiniChatDemo.git)
2. Crie e ative o ambiente virtual
- py -3.11 -m venv venv
- venv\Scripts\activate
3. Instale as dependÃªncias

- pip install -r requirements.txt
4. Baixe o modelo de IA
- Acesse a pÃ¡gina do modelo:

- ğŸ‘‰ https://huggingface.co/TheBloke/Llama-2-7B-Chat-GGUF

- Baixe o arquivo recomendado:

- llama-2-7b-chat.Q4_K_M.gguf

- Coloque este arquivo dentro da pasta "model/" e renomeie o arquivo para model.gguf


## ğŸ“„ LicenÃ§a
* Este projeto Ã© livre para uso pessoal, educacional e para portfÃ³lio.